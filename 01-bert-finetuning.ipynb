{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad75f8f-7360-4ee0-afa3-8ed4a97a7125",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (4.46.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (4.67.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from peft) (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from transformers->peft) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5067bd-481b-4c87-bdf7-72e41806290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngoum\\anaconda3\\envs\\dl-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb18d5c6-62fe-4c9c-994c-d58db15b6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased' #'bert-base-uncased'\n",
    "device = \"cuda\" if torch.device(\"cuda\") else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed0b39d-c591-4d9a-8cdd-bdb975c60e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2e51a-9364-4e5c-9d2b-31b922cc8c84",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1c6b25-c782-4b9b-bbd2-77f9d7ab023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Preprocess dataset\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])  # Drop ID column\n",
    "    df = df[~df[\"text\"].isnull()]  # Drop articles with no text\n",
    "    \n",
    "    # Map bias to numeric value\n",
    "    bias_mapping = {'left': 1, 'center': 0, 'right': 1}\n",
    "    df['bias_numeric'] = df['bias_rating'].map(bias_mapping)\n",
    "    \n",
    "    # Group articles by event\n",
    "    unique_titles = df['title'].unique()\n",
    "    title_to_event_id = {title: idx for idx, title in enumerate(unique_titles)}\n",
    "    df['event_id'] = df['title'].map(title_to_event_id)\n",
    "    \n",
    "    df.loc[df[\"tags\"] == \"[]\", \"tags\"] = \"N/A\"  # Handle missing tags/topics\n",
    "    df[\"tags\"] = df[\"tags\"].apply(lambda x: re.sub(\"\\[|\\]|\\'\", \"\", x))\n",
    "    \n",
    "    # Select columns\n",
    "    variables = [\"event_id\", \"tags\", \"heading\", \"text\", \"bias_numeric\"]\n",
    "    df = df[variables]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5927243-1af8-4630-8d33-74f16a2f0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_inputs(df):\n",
    "    df_ = df.copy()\n",
    "    df_[\"input_text\"] = \"[CLS] Heading: \" + df_['heading'] + \" [SEP] Content: \" + df_['text'] + \" [SEP]\"\n",
    "    #df_[\"input_text\"] = \"[CLS] Tags: \" + df_['tags'] + \" [SEP] Heading: \" + df_['heading'] + \" [SEP] Content: \" + df_['text'] + \" [SEP]\"\n",
    "    return df_[[\"input_text\", \"bias_numeric\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3534a1-16ef-428a-83fa-89fd5560f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df):\n",
    "    dataset = construct_inputs(df)\n",
    "    dataset = Dataset.from_pandas(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c258d0-3ad5-412c-bdbf-9c771c27133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(df, test_size=0.1, eval_size=0.1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    grouped = df.groupby('event_id')\n",
    "    \n",
    "    # Split groups into train, eval, and test sets\n",
    "    train_groups, test_groups = train_test_split(list(grouped), test_size=test_size, random_state=42)\n",
    "    train_groups, eval_groups = train_test_split(train_groups, test_size=eval_size, random_state=42)\n",
    "    \n",
    "    # Create datasets from the groups\n",
    "    train_df = pd.concat([group[1] for group in train_groups])\n",
    "    eval_df = pd.concat([group[1] for group in eval_groups])\n",
    "    test_df = pd.concat([group[1] for group in test_groups])\n",
    "    \n",
    "    # Convert to Datasets\n",
    "    train_data = build_dataset(train_df)\n",
    "    eval_data = build_dataset(eval_df)\n",
    "    test_data = build_dataset(test_df)\n",
    "    \n",
    "    return train_data, eval_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34780f03-1d81-4ed7-9883-e39686ece2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(df, frac=0.1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    grouped = df.groupby('event_id')\n",
    "    # Split groups\n",
    "    groups, _ = train_test_split(list(grouped), test_size=1.0-frac, random_state=42)\n",
    "    # Create datasets from the groups\n",
    "    new_df = pd.concat([group[1] for group in groups])\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea68a3-fcda-4615-baa4-a5bb0ef3fc28",
   "metadata": {},
   "source": [
    "Load CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74f1e86-e911-4aa5-9f51-e12751c319f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21747, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_csv_data(data_path=\"data/allsides_balanced_news_headlines-texts.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da643f4b-d2ce-41e3-b5b2-cb9ae524e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10868, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Significantly reduce the number of elements for testing purposes\n",
    "df = reduce_dataset(df, frac=0.5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f207d21-2fc2-4629-a157-c5b17d6a143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "3    3598\n",
       "2      31\n",
       "6       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"event_id\"].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a18c91c-c13b-4b18-9eb2-07cae35f8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, eval_data, test_data = load_datasets(df, test_size=0.3, eval_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6856272-4861-4430-8981-6ed6498cc708",
   "metadata": {},
   "source": [
    "Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b683d4f4-d1fa-4101-a81d-d2543b9f0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20090887-1f8c-468a-8ae8-20ccea12c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    def tokenize_function(examples):\n",
    "        # Tokenize the input_text to get input_ids and attention_mask\n",
    "        return tokenizer(examples['input_text'], padding='max_length', truncation=True, max_length=512)\n",
    "    \n",
    "    tokenized = dataset.map(tokenize_function, batched=True).rename_column(\"bias_numeric\", \"labels\")\n",
    "    tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9da95f0f-d5b6-434f-99ed-389368b5e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 6845/6845 [00:01<00:00, 4483.27 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 761/761 [00:00<00:00, 4825.03 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 3262/3262 [00:00<00:00, 3978.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = preprocess_dataset(train_data)\n",
    "tokenized_eval = preprocess_dataset(eval_data)\n",
    "tokenized_test = preprocess_dataset(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2c975-e0a9-4c96-a5d7-0c6d315798e0",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71be3be9-0b6d-4944-ae84-d8d76233d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model with a classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245f758-89ac-4d09-b156-e9d9793645eb",
   "metadata": {},
   "source": [
    "Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a9e02e-b9be-4d59-9014-89be2a514020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.05,\n",
    "    logging_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    report_to=[\"none\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf9b219f-002a-4e49-ad4a-4a809372fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0038cbc-ae00-472a-ac39-032a7eb0d5f6",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f39e82-c166-4c61-a8cb-ced270214bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17120' max='17120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17120/17120 42:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.594700</td>\n",
       "      <td>0.535162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.517653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.622643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.824195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.998823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>1.244926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>1.439857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>1.572540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>1.570349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.701423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17120, training_loss=0.2840318426188932, metrics={'train_runtime': 2567.7064, 'train_samples_per_second': 26.658, 'train_steps_per_second': 6.667, 'total_flos': 9067555142092800.0, 'train_loss': 0.2840318426188932, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b9c95-a86a-41b4-9e32-1e5c57772b5e",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ce98b0-a6f4-4cee-9a88-7a0ac797c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1007' max='191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [191/191 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5176530480384827, 'eval_runtime': 9.5508, 'eval_samples_per_second': 79.679, 'eval_steps_per_second': 19.998, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ecf32e6-dc73-4485-94d3-c5396861ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # F1 Score (using weighted average for multiclass classification)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"kappa\": kappa\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "503b27f8-4253-46c9-be6c-2426455a4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the compute_metrics function to the trainer\n",
    "trainer.compute_metrics = compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b4490e3-b20e-46bd-a981-8cd1246b214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.4962586760520935, 'eval_accuracy': 0.826486817903127, 'eval_f1': 0.7939300766051058, 'eval_kappa': 0.2513470378143764, 'eval_runtime': 45.5532, 'eval_samples_per_second': 71.609, 'eval_steps_per_second': 17.913, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.evaluate(eval_dataset=tokenized_test)\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667d16a-86a3-4a7b-b94f-0ce342ef1816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl-env)",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
