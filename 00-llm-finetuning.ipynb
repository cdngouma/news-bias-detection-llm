{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06f5fc8-0fa4-4bd5-b5c9-9dd0a68d82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922c3f5b-21d6-4d9b-86ed-a65e972b8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngoum\\anaconda3\\envs\\llm-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, LlamaForSequenceClassification, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0d0331-af2c-454d-be33-832a33f2b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a42419-0b81-4c27-815c-12c4749bb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    # Drop ID column\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "    # Drop articles with no text\n",
    "    df = df[~df[\"text\"].isnull()]\n",
    "    # Map bias to numeric value\n",
    "    bias_mapping = {'left': 1, 'center': 0, 'right': 2}\n",
    "    df['bias_numeric'] = df['bias_rating'].map(bias_mapping)\n",
    "    # Group articles by event\n",
    "    unique_titles = df['title'].unique()\n",
    "    title_to_event_id = {title: idx for idx, title in enumerate(unique_titles)}\n",
    "    df['event_id'] = df['title'].map(title_to_event_id)\n",
    "    # Handle missing tags/topics\n",
    "    df.loc[df[\"tags\"] == \"[]\", \"tags\"] = \"N/A\"\n",
    "    # Select columns\n",
    "    variables = [\"event_id\", \"tags\", \"heading\", \"text\", \"bias_numeric\"]\n",
    "    df = df[variables]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c9ca07-6aa8-4b87-93b2-7109a2b875bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(example):\n",
    "    input_text = (\n",
    "        f\"Article Title: {example['heading']}\\n\"\n",
    "        f\"Topics: {example['tags']}\\n\"\n",
    "        f\"Content: {example['text']}\\n\"\n",
    "        \"What is the political bias of this article? (Options: 1 = Left, 0 = Center, 2 = Right)\"\n",
    "    )\n",
    "    return {'input_text': input_text, 'label': int(example['bias_numeric'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303a386f-2782-483b-88b4-9e4a7f8355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df):\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset = dataset.map(preprocess_dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1011d545-7689-49c4-824a-4b011034bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(df, test_size=0.1, eval_size=0.1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    grouped = df.groupby('event_id')\n",
    "    # Split groups into train, eval, and test sets\n",
    "    train_groups, test_groups = train_test_split(list(grouped), test_size=test_size, random_state=42)\n",
    "    train_groups, eval_groups = train_test_split(train_groups, test_size=eval_size, random_state=42)\n",
    "    # Create datasets from the groups\n",
    "    train_df = pd.concat([group[1] for group in train_groups])\n",
    "    eval_df = pd.concat([group[1] for group in eval_groups])\n",
    "    test_df = pd.concat([group[1] for group in test_groups])\n",
    "    # Convert to Datasets\n",
    "    train_data = build_dataset(train_df)\n",
    "    eval_data = build_dataset(eval_df)\n",
    "    test_data = build_dataset(test_df)\n",
    "    \n",
    "    return train_data, eval_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0061f79-ed67-4e3c-bbaf-ae0931321b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(df, frac=0.1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    grouped = df.groupby('event_id')\n",
    "    # Split groups\n",
    "    groups, _ = train_test_split(list(grouped), test_size=1.0-frac, random_state=42)\n",
    "    # Create datasets from the groups\n",
    "    new_df = pd.concat([group[1] for group in groups])\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27bf9c-e4a7-413e-8f44-9e5172366de3",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99defd7-860f-4f22-9dd5-bf85a086ceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21747, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_csv_data(data_path=\"data/allsides_balanced_news_headlines-texts.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d15cfbd-d54a-4f15-89f8-6d2247b4fc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Significantly reduce the number of elements for testing purposes\n",
    "df = reduce_dataset(df, frac=0.35)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdcc2fcc-2d07-47c2-90b8-7286af5e8b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "      <th>bias_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19486</th>\n",
       "      <td>6504</td>\n",
       "      <td>['Presidential Elections', '2020 Election', '2...</td>\n",
       "      <td>Debates commission plans to cut off mics if Tr...</td>\n",
       "      <td>The commission that oversees the general elect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19487</th>\n",
       "      <td>6504</td>\n",
       "      <td>['Presidential Elections', '2020 Election', '2...</td>\n",
       "      <td>Debate commission considering cutting candidat...</td>\n",
       "      <td>The presidential debate commission is consider...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19488</th>\n",
       "      <td>6504</td>\n",
       "      <td>['Presidential Elections', '2020 Election', '2...</td>\n",
       "      <td>Presidential debate: Rules to change after Tru...</td>\n",
       "      <td>The commission that oversees US presidential d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20840</th>\n",
       "      <td>6958</td>\n",
       "      <td>['Gun Control', 'Gun Rights', 'Background Chec...</td>\n",
       "      <td>A Universal-Background-Check Law Would Not Vio...</td>\n",
       "      <td>The terrible shootings in Gilroy, El Paso, and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20841</th>\n",
       "      <td>6958</td>\n",
       "      <td>['Gun Control', 'Gun Rights', 'Background Chec...</td>\n",
       "      <td>Trump calls for 'intelligent background checks...</td>\n",
       "      <td>President Trump on Friday called for \"intellig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_id                                               tags  \\\n",
       "19486      6504  ['Presidential Elections', '2020 Election', '2...   \n",
       "19487      6504  ['Presidential Elections', '2020 Election', '2...   \n",
       "19488      6504  ['Presidential Elections', '2020 Election', '2...   \n",
       "20840      6958  ['Gun Control', 'Gun Rights', 'Background Chec...   \n",
       "20841      6958  ['Gun Control', 'Gun Rights', 'Background Chec...   \n",
       "\n",
       "                                                 heading  \\\n",
       "19486  Debates commission plans to cut off mics if Tr...   \n",
       "19487  Debate commission considering cutting candidat...   \n",
       "19488  Presidential debate: Rules to change after Tru...   \n",
       "20840  A Universal-Background-Check Law Would Not Vio...   \n",
       "20841  Trump calls for 'intelligent background checks...   \n",
       "\n",
       "                                                    text  bias_numeric  \n",
       "19486  The commission that oversees the general elect...             1  \n",
       "19487  The presidential debate commission is consider...             2  \n",
       "19488  The commission that oversees US presidential d...             0  \n",
       "20840  The terrible shootings in Gilroy, El Paso, and...             2  \n",
       "20841  President Trump on Friday called for \"intellig...             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa4027c-bddd-4f80-9a9c-c0f809d6f9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"event_id\").count()[\"text\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a365af56-a284-4f4d-b37a-28437089cfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 4793/4793 [00:00<00:00, 10923.79 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 532/532 [00:00<00:00, 11636.99 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2288/2288 [00:00<00:00, 10345.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, eval_data, test_data = load_datasets(df, test_size=0.3, eval_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd66dec-4499-4222-be9a-a581ca83b473",
   "metadata": {},
   "source": [
    "### Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2019b0be-98f3-4b00-987f-5d00353a85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'unsloth/Llama-3.2-1B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3940d32b-41d8-4481-ae7b-81a18d82cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c2d2c-30b3-4abb-bfcb-d24d61df209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    print(\"No padding token\")\n",
    "    #tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "else:\n",
    "    print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6f188e2-8360-4bf6-830f-5654c45284ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Tokenize the input_text to get input_ids and attention_mask\n",
    "    encoding = tokenizer(examples['input_text'], padding='max_length', truncation=True, max_length=512)\n",
    "    encoding['label'] = examples['label']  # Add the label to the encoding\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "041000b2-b264-428d-94a5-7ffe4ff5284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 4793/4793 [00:00<00:00, 5432.15 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 532/532 [00:00<00:00, 5232.31 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 2288/2288 [00:00<00:00, 5633.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.67 s\n",
      "Wall time: 1.86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tokenize the datasets\n",
    "tokenized_train = train_data.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_data.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f04675-f068-4b7d-bfc3-3fbf9b8bf11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956c698-4462-439d-8a7a-b80eaddec475",
   "metadata": {},
   "source": [
    "### Prepare LoRa for fine-turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8df1107c-4b0e-4f75-a826-3ee2e26e8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare LoRa configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                       # Rank of LoRa matrices\n",
    "    lora_alpha=32,             # Scaling factor\n",
    "    lora_dropout=0.1,          # Dropout probability for LoRa\n",
    "    bias=\"none\",               # Bias configuration\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]  # Target layers for LoRa in LLaMa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb4ca8-1678-416a-aef4-59e2a8a2edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./outputs\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=6,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    fp16=True,  # Enable mixed-precision training for faster performance\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to='none' # Disable W&B logging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88a83f-0265-42f1-87bd-46d24a8492a1",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ef063a2-5a30-44b8-927b-76a029e29c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aa2a536-597f-48ea-b9c9-f2301fe7b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at unsloth/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained LLaMa model for sequence classification\n",
    "model = LlamaForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4997837-6993-4663-b2a9-39fd99f81cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "813e1838-6070-4f03-a454-04973448cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRa to the model\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "365ba448-bdfa-4adf-b93d-b09f01282a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88467b-b926-45ea-91d3-90afab60f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975adb79-df08-40f5-80d0-b10124abd6e2",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d4208-b21d-49c5-85bc-286ce4f973c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./outputs\")\n",
    "tokenizer.save_pretrained(\"./outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b31a7-2e6b-4f59-a3d6-af8e79cabe52",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d1452-4727-4296-833d-05d0ee01dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaForSequenceClassification.from_pretrained(\"./outputs\")\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f14ac-0ddb-485d-bd00-420071c7d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467048d5-f42a-4efe-9525-4df6ccc4664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72146a99-c356-4a6b-a351-f9bb2c9d34bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env (Python)",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
